{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3  ('env': venv)",
   "metadata": {
    "interpreter": {
     "hash": "ffb072dfce72f6f080b2d6b8984a56656ee2b807f16892b8b0f111185ea2e04f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "corpus = pd.read_csv(\"/Users/piyushmundhra/Desktop/cs173/words/en-basic\", sep='\\n', header=None)\n",
    "corpus[1] = 0\n",
    "corpus.columns = ['words', 'distance']\n",
    "print(list(corpus))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['words', 'distance']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    regex = r'\\b[a-zA-Z]*\\b'\n",
    "    words = pd.Series(re.findall(regex, string))\n",
    "    words = words[words != '']\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0         I\n2        am\n4         a\n6     human\n8      fsas\n10        e\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(\"I, am a human;fsas,/e\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Included a helper function to ease debugging\n",
    "def editDistanceHelper(word1, word2):\n",
    "\n",
    "    word1 = \" \" + word1\n",
    "    word2 = \" \" + word2\n",
    "\n",
    "    # Setting up edit distance matrix and inputting given values (constructing from null string)\n",
    "    rows = []\n",
    "    rows[:] = word1\n",
    "    cols = []\n",
    "    cols[:] = word2\n",
    "\n",
    "    matrix = pd.DataFrame(np.zeros((len(word1), len(word2))), columns=cols, index=rows)\n",
    "    for i in range (0, len(word1)): \n",
    "        matrix.iloc[i,0] = i\n",
    "    for i in range (0, len(word2)):\n",
    "        matrix.iloc[0,i] = i\n",
    "\n",
    "\n",
    "    # Computing the rest of the values based on the assumption that editing, deleting, and inserting a character all have the same weight/cost\n",
    "    for i in range (1, len(word1)):\n",
    "        for j in range (1, len(word2)):\n",
    "            matrix.iloc[i,j] = min(matrix.iloc[i-1,j-1], matrix.iloc[i-1,j], matrix.iloc[i,j-1])\n",
    "            if(word1[i] != word2[j]):\n",
    "                matrix.iloc[i,j] = matrix.iloc[i,j] + 1\n",
    "    return matrix\n",
    "\n",
    "# Will return integer edit distance value\n",
    "def editDistance(word1, word2):\n",
    "    return editDistanceHelper(word1, word2).iloc[len(word1), len(word2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closestWords(word, corpus):\n",
    "    a = len(word) + 1\n",
    "    b = len(word) - 1\n",
    "    temp = corpus.loc[(corpus.words.str.len() <= a) & (corpus.words.str.len() >= b)]\n",
    "    for c in range (0, temp.shape[0]):\n",
    "        temp.iloc[c,1] = editDistance(temp.iloc[c,0], word)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggestWords(word, corpus, num):\n",
    "    temp = closestWords(word, corpus)\n",
    "    temp = temp.sort_values(by='distance', ascending=True)\n",
    "    return temp.iloc[0:num,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck(sentence, corpus):\n",
    "    for w in tokenize(sentence):\n",
    "        if(not(w in corpus['words'].unique())): \n",
    "            print('Suggestions for ', w, ': ', end=' ')\n",
    "            close = suggestWords(w, corpus, 3)\n",
    "            for cw in close['words']:\n",
    "                print(cw, end= ', ')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Suggestions for  amoyt :  about, almost, among, \n",
      "Suggestions for  ablr :  able, all, air, \n",
      "Suggestions for  criminal :  chemical, writing, driving, \n"
     ]
    }
   ],
   "source": [
    "spellcheck('I table all, ;amoyt ablr smooth criminal drink water', corpus)"
   ]
  }
 ]
}